---
title: "CLASS10"
author: "Berenice R. Leal"
date: "2/6/2020"
output: github_document
---

First we need to import (i.e. read our input data)
```{r}
wisc.df <- read.csv("WisconsinCancer.csv")
head(wisc.df)
```

In columnd 32-34 there is an X with NA. We do not want this column to affect our data. We want to not use it to just work with numbers. 

```{r}
#There are some funkey things in this dataset that we will ignore for our analysis. This includes the first and second ID and Diagnosis columns and the finny last X column

wisc.data <- as.matrix( wisc.df[,3:32])
head(wisc.data)
```

Q. How many patients do we have data for?

```{r}
nrow(wisc.data)
```


Q. How many cancer and non-cancer?

```{r}
wisc.df$diagnosis

```

```{r}
#Table will make a table and we will know the exact number

table(wisc.df$diagnosis)
```

Q3. How many variables/features in the data are suffixed with _mean?
For this I will turn to the 'grep()' function and look at the help page

```{r}
colnames(wisc.data)     #this showsa me the names in columns... you can see the word _mean

grep("_mean", colnames(wisc.data), value=T)

#it gives numbers only... 10 , if we add value=T it gives u the actual names
```



```{r}
length(grep("_mean", colnames(wisc.data)))
#just tells you how many of "_mean"
```



## Principal Component Analysis

Before we turn to PCA we need to think, or consider, whether we should SCALE our input.

It is important to check if the data need to be scaled before performing PCA. Recall two common reasons for scaling data include:

The input variables use different units of measurement.

- The input variables have significantly different variances.
- Check the mean and standard deviation of the features (i.e. columns) of the wisc.data to determine if the data should be scaled. Use the `colMeans()` and `apply()` functions like you’ve done before.

```{r}

#1 for the row and 2 for columns... it will compy the sd for every column

#round will round up to 2 sfigures)

round( apply(wisc.df,  2, sd), 2)
```
Looks like we need to set scale=TRUE!!


```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp( wisc.data, scale=TRUE )
summary(wisc.pr)


# in proportion variance we can see that PC1 describes 41% of the content, and PC2 %19, adding more PCs will describe even better. 
```


> Q. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

The 1st PC captures 44.27% of the original variance. Note that 72.6% is captured in the first 3 PCs...


Lets make some figures...

```{r}
biplot(wisc.pr)
```

That is a hot mess! We need to do our own PC1 vs PC2 plot and lets color by the diagnosis.

```{r}
attributes(wisc.pr)
```

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=wisc.df$diagnosis)

#malignant is red

abline(h=0, col="gray", lty=2)
abline(v=0, col="gray", lty=2)


```


###Cluster in PC space
First let's see if we can cluster original data
kmeans(x, centers=#, nstart=20 -to run multimple times)

hclust()

-we cannot give the data just as input -

```{r}

#wisc.data is our input data... 

wisc.hc <- hclust(dist(wisc.data))
plot(wisc.hc)


```

This does not look good! Let's try and combine the results of PCA with clustering...

#instead of using wisc.data we can use the results of PCA

-Clustering the data by itself isnt very useful...
```{r}

```


Let’s see if PCA improves or degrades the performance of hierarchical clustering.

Using the minimum number of principal components required to describe at least 90% of the variability in the data, create a hierarchical clustering model with the linkage method="ward.D2". We use Ward’s criterion here because it is based on multidimensional variance like principal components analysis. Assign the results to wisc.pr.hclust.


```{r}
wisc.pr.hclust <- hclust( dist(wisc.pr$x[,1:3]), method="ward.D2" )


plot(wisc.pr.hclust)

#because everything is so on top of everything... use function cutree

```


To get our clusters out of this tree we need to CUT it with the `cutree()` function.

```{r}
grps3 <- cutree(wisc.pr.hclust, k=2)
table(grps3)
```

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=grps3)
```

We can use the `table()` function to compare the $diagnosis vector with our cluster results vector.

```{r}
table(grps3, wisc.df$diagnosis)
```


```{r}
table(grps3, wisc.df$diagnosis)
```

##  Prediction
We will use the predict() function that will take our PCA model from before and new cancer cell data and project that data onto our PCA space.

```{r}

#!!!! I couldn run the page with this line....
#new <- read.csv("new_samples.cs")
#new
```

Use the `predict()` function with our previous PCA model and new data...

```{r}
#npc <- predict(wisc.pr, newdata=new)
#npc
```

Now draw the PCA plot again and add our new data:


```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=wisc.df$diagnosis)
#points(npc[,1], npc[,2], col="blue", pch=15)
```



```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=wisc.df$diagnosis)
#points(npc[,1], npc[,2], col="blue", pch=15)
```






